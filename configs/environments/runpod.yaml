# RunPod GPU Environment Configuration

# System Configuration
environment:
  name: "runpod"
  type: "production"
  
# Hardware Settings
hardware:
  gpu_required: true
  gpu_memory_min: "50GB"  
  cuda_version: "11.8"
  
# Path Configuration
paths:
  base_dir: "${PROJECT_ROOT}"
  data_dir: "${PROJECT_ROOT}/data"
  images_dir: "${PROJECT_ROOT}/data/images"
  ground_truth_path: "${PROJECT_ROOT}/data/ground_truth.csv"
  results_dir: "${PROJECT_ROOT}/results/raw"
  model_cache_dir: "/cache"  # RunPod persistent storage
  
# Model Settings
model_defaults:
  precision: "bfloat16"  # Use bfloat16 as in your successful notebook
  device: "cuda:0"
  quantization: "16-bit"  # Optional quantization
  batch_size: 1  # Adjust based on GPU memory
  
# Execution Settings
execution:
  parallel_processes: 1  # GPU work is already parallel
  checkpoint_frequency: 1  # Save results after each image (for reliability)
  verbose_logging: true
  gpu_monitoring: true
  
# Dependencies 
dependencies:
  transformers: "==4.34.0"  # Exact versions that worked on RunPod
  torch: "==2.0.1"
  accelerate: "==0.21.0"
  bitsandbytes: ">=0.41.1"  # For quantization
  sentencepiece: ">=0.1.99"